{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.3em; font-weight: 300;\">This kernel tries to apply the recent winning solution of Google Landmark Recognition and Retrieval by <a href=\"https://www.kaggle.com/christofhenkel\">@dieter</a> to the current Pawpularity Challenge</span><br><span style=\"color: #000508; font-family: Segoe UI; font-size: 1.3em; font-weight: 300;\">Winning Solution can be found <a href=\"https://www.kaggle.com/c/landmark-recognition-2021/discussion/277098\">here</a></span><br><br>\n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.3em; font-weight: 300;\">This has also been recently shared by <a href=\"https://www.kaggle.com/cdeotte\">@cdeotte</a> in the following <a href=\"https://www.kaggle.com/c/petfinder-pawpularity-score/discussion/277917\">discussion</a></span><br><br>\n\n\n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.3em; font-weight: 300;\">I tried to reproduce the model referring to the following tweet by <a href=\"https://www.kaggle.com/christofhenkel\">@dieter</a></span><br>\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\" style=\"color: #000508; font-family: Segoe UI; font-size: 1.3em; font-weight: 300;\">exactly. I used your excellent timm library for it<br>backbone = timm.create_model(swin_base_patch4_window7_224)<br>embedder = timm.create_model(tf_efficientnet_b5,out_indices=[2])<br>backbone.patch_embed = HybridEmbed(embedder)</p>&mdash; Dieter (@kagglingdieter) <a href=\"https://twitter.com/kagglingdieter/status/1444521143499689997?ref_src=twsrc%5Etfw\">October 3, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br>\n\n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.3em; font-weight: 300;\">I haven't got great results yet, the following things can be tried further to improve performance:</span><br>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.3em; font-weight: 300;\">Better learning rate scheduling</span><br>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.3em; font-weight: 300;\">First training transformer and CNN separately and then training them jointly as in the winning solution</span><br>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.3em; font-weight: 300;\">Trying classification instead of regression</span><br>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.3em; font-weight: 300;\">Try a SVR head as suggested <a href=\"https://www.kaggle.com/c/petfinder-pawpularity-score/discussion/276724\">here</a></span><br>\n\n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.3em; font-weight: 300;\">There is a lot of room for improvement, I hope this helps...</span><br>","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/rwightman/pytorch-image-models\n!pip install --upgrade wandb","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-18T13:50:33.77811Z","iopub.execute_input":"2021-10-18T13:50:33.778578Z","iopub.status.idle":"2021-10-18T13:50:57.835548Z","shell.execute_reply.started":"2021-10-18T13:50:33.778457Z","shell.execute_reply":"2021-10-18T13:50:57.834764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport copy\nimport time\nimport random\nfrom PIL import Image\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\n\n# Utils\nimport joblib\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n# Sklearn Imports\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nimport timm\n\n# Albumentations for augmentations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nc_ = Fore.CYAN\nsr_ = Style.RESET_ALL\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:50:57.839264Z","iopub.execute_input":"2021-10-18T13:50:57.83949Z","iopub.status.idle":"2021-10-18T13:51:05.059136Z","shell.execute_reply.started":"2021-10-18T13:50:57.839461Z","shell.execute_reply":"2021-10-18T13:51:05.058195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"wandb_api\")\n    wandb.login(key=api_key)\n    anony = None\nexcept:\n    anony = \"must\"\n    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:05.060473Z","iopub.execute_input":"2021-10-18T13:51:05.060737Z","iopub.status.idle":"2021-10-18T13:51:06.306254Z","shell.execute_reply.started":"2021-10-18T13:51:05.060703Z","shell.execute_reply":"2021-10-18T13:51:06.305472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = \"../input/petfinder-pawpularity-score\"\nTRAIN_DIR = \"../input/petfinder-pawpularity-score/train\"\nTEST_DIR = \"../input/petfinder-pawpularity-score/test\"","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:06.30957Z","iopub.execute_input":"2021-10-18T13:51:06.309805Z","iopub.status.idle":"2021-10-18T13:51:06.316286Z","shell.execute_reply.started":"2021-10-18T13:51:06.309778Z","shell.execute_reply":"2021-10-18T13:51:06.315477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG = dict(\n    seed = 42,\n    backbone = 'swin_base_patch4_window7_224',\n    embedder = 'tf_efficientnet_b4_ns',\n    train_batch_size = 16,\n    valid_batch_size = 32,\n    img_size = 448,\n    epochs = 5,\n    learning_rate = 1e-4,\n    scheduler = 'CosineAnnealingLR',\n    min_lr = 1e-6,\n    T_max = 100,\n#     T_0 = 25,\n#     warmup_epochs = 0,\n    weight_decay = 1e-6,\n    n_accumulate = 1,\n    n_fold = 5,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n    competition = 'PetFinder',\n    _wandb_kernel = 'deb'\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:06.318911Z","iopub.execute_input":"2021-10-18T13:51:06.319258Z","iopub.status.idle":"2021-10-18T13:51:06.370604Z","shell.execute_reply.started":"2021-10-18T13:51:06.319222Z","shell.execute_reply":"2021-10-18T13:51:06.369776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed = 42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:06.37411Z","iopub.execute_input":"2021-10-18T13:51:06.374324Z","iopub.status.idle":"2021-10-18T13:51:06.385949Z","shell.execute_reply.started":"2021-10-18T13:51:06.3743Z","shell.execute_reply":"2021-10-18T13:51:06.385138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_file_path(id):\n    return f\"{TRAIN_DIR}/{id}.jpg\"","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:06.388962Z","iopub.execute_input":"2021-10-18T13:51:06.389231Z","iopub.status.idle":"2021-10-18T13:51:06.395945Z","shell.execute_reply.started":"2021-10-18T13:51:06.389199Z","shell.execute_reply":"2021-10-18T13:51:06.395126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(f\"{ROOT_DIR}/train.csv\")\ndf['file_path'] = df['Id'].apply(get_train_file_path)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:06.397375Z","iopub.execute_input":"2021-10-18T13:51:06.397625Z","iopub.status.idle":"2021-10-18T13:51:06.445031Z","shell.execute_reply.started":"2021-10-18T13:51:06.397594Z","shell.execute_reply":"2021-10-18T13:51:06.444241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_cols = [col for col in df.columns if col not in ['Id', 'Pawpularity', 'file_path']]","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:06.447683Z","iopub.execute_input":"2021-10-18T13:51:06.447872Z","iopub.status.idle":"2021-10-18T13:51:06.454147Z","shell.execute_reply.started":"2021-10-18T13:51:06.44785Z","shell.execute_reply":"2021-10-18T13:51:06.453418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Code taken from <a href=\"https://www.kaggle.com/tolgadincer/continuous-target-stratification?rvi=1&scriptVersionId=52551118&cellId=6\">this notebook</a></span>","metadata":{}},{"cell_type":"code","source":"def create_folds(df, n_s=5, n_grp=None):\n    df['kfold'] = -1\n    \n    if n_grp is None:\n        skf = KFold(n_splits=n_s, random_state=CONFIG['seed'])\n        target = df['Pawpularity']\n    else:\n        skf = StratifiedKFold(n_splits=n_s, shuffle=True, random_state=CONFIG['seed'])\n        df['grp'] = pd.cut(df['Pawpularity'], n_grp, labels=False)\n        target = df.grp\n    \n    for fold_no, (t, v) in enumerate(skf.split(target, target)):\n        df.loc[v, 'kfold'] = fold_no\n\n    df = df.drop('grp', axis=1)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:06.45746Z","iopub.execute_input":"2021-10-18T13:51:06.457691Z","iopub.status.idle":"2021-10-18T13:51:06.608714Z","shell.execute_reply.started":"2021-10-18T13:51:06.457667Z","shell.execute_reply":"2021-10-18T13:51:06.607879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = create_folds(df, n_s=CONFIG['n_fold'], n_grp=14)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:06.610062Z","iopub.execute_input":"2021-10-18T13:51:06.610551Z","iopub.status.idle":"2021-10-18T13:51:06.656591Z","shell.execute_reply.started":"2021-10-18T13:51:06.610512Z","shell.execute_reply":"2021-10-18T13:51:06.655865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularityDataset(Dataset):\n    def __init__(self, root_dir, df, transforms=None):\n        self.root_dir = root_dir\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.targets = df['Pawpularity'].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_path = self.file_names[index]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        target = self.targets[index]\n        \n        if self.transforms:\n            img = self.transforms(image=img)[\"image\"]\n            \n        return img, target","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:06.657804Z","iopub.execute_input":"2021-10-18T13:51:06.658053Z","iopub.status.idle":"2021-10-18T13:51:06.666738Z","shell.execute_reply.started":"2021-10-18T13:51:06.658019Z","shell.execute_reply":"2021-10-18T13:51:06.665786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h2 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Augmentations</h2>","metadata":{}},{"cell_type":"code","source":"data_transforms = {\n    \"train\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.HorizontalFlip(p=0.5),\n        A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n        ToTensorV2()], p=1.),\n    \n    \"valid\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n        ToTensorV2()], p=1.)\n}","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-18T13:51:06.6684Z","iopub.execute_input":"2021-10-18T13:51:06.668808Z","iopub.status.idle":"2021-10-18T13:51:06.678832Z","shell.execute_reply.started":"2021-10-18T13:51:06.668766Z","shell.execute_reply":"2021-10-18T13:51:06.677969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Models","metadata":{}},{"cell_type":"code","source":"class HybridEmbed(nn.Module):\n    \"\"\" CNN Feature Map Embedding\n    Extract feature map from CNN, flatten, project to embedding dim.\n    \"\"\"\n    def __init__(self, backbone, img_size=224, patch_size=1, feature_size=None, in_chans=3, embed_dim=768):\n        super().__init__()\n        assert isinstance(backbone, nn.Module)\n        img_size = (img_size, img_size)\n        patch_size = (patch_size, patch_size)\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.backbone = backbone\n        if feature_size is None:\n            with torch.no_grad():\n                # NOTE Most reliable way of determining output dims is to run forward pass\n                training = backbone.training\n                if training:\n                    backbone.eval()\n                o = self.backbone(torch.zeros(1, in_chans, img_size[0], img_size[1]))\n                if isinstance(o, (list, tuple)):\n                    o = o[-1]  # last feature if backbone outputs list/tuple of features\n                feature_size = o.shape[-2:]\n                feature_dim = o.shape[1]\n                backbone.train(training)\n        else:\n            feature_size = (feature_size, feature_size)\n            if hasattr(self.backbone, 'feature_info'):\n                feature_dim = self.backbone.feature_info.channels()[-1]\n            else:\n                feature_dim = self.backbone.num_features\n        assert feature_size[0] % patch_size[0] == 0 and feature_size[1] % patch_size[1] == 0\n        self.grid_size = (feature_size[0] // patch_size[0], feature_size[1] // patch_size[1])\n        self.num_patches = self.grid_size[0] * self.grid_size[1]\n        self.proj = nn.Conv2d(feature_dim, embed_dim, kernel_size=patch_size, stride=patch_size)\n\n    def forward(self, x):\n        x = self.backbone(x)\n        if isinstance(x, (list, tuple)):\n            x = x[-1]  # last feature if backbone outputs list/tuple of features\n        x = self.proj(x).flatten(2).transpose(1, 2)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:06.683217Z","iopub.execute_input":"2021-10-18T13:51:06.683452Z","iopub.status.idle":"2021-10-18T13:51:06.697604Z","shell.execute_reply.started":"2021-10-18T13:51:06.683418Z","shell.execute_reply":"2021-10-18T13:51:06.696762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularityModel(nn.Module):\n    def __init__(self, backbone, embedder, pretrained=True):\n        super(PawpularityModel, self).__init__()\n        self.backbone = timm.create_model(backbone, pretrained=pretrained)\n        self.embedder = timm.create_model(embedder, features_only=True, out_indices=[2], pretrained=pretrained)\n        self.backbone.patch_embed = HybridEmbed(self.embedder, img_size=CONFIG['img_size'], embed_dim=128)\n        self.n_features = self.backbone.head.in_features\n        self.backbone.reset_classifier(0)\n        self.fc = nn.Linear(self.n_features, CONFIG['num_classes'])\n\n    def forward(self, images):\n        features = self.backbone(images)              # features = (bs, embedding_size)\n        output = self.fc(features)                    # outputs  = (bs, num_classes)\n        return output\n    \nmodel = PawpularityModel(CONFIG['backbone'], CONFIG['embedder'])\nmodel.to(CONFIG['device']);","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:06.699062Z","iopub.execute_input":"2021-10-18T13:51:06.699326Z","iopub.status.idle":"2021-10-18T13:51:22.257611Z","shell.execute_reply.started":"2021-10-18T13:51:06.699294Z","shell.execute_reply":"2021-10-18T13:51:22.256842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test\nimg = torch.randn(1, 3, CONFIG['img_size'], CONFIG['img_size']).to(CONFIG['device'])\nmodel(img)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:22.258979Z","iopub.execute_input":"2021-10-18T13:51:22.259296Z","iopub.status.idle":"2021-10-18T13:51:22.549641Z","shell.execute_reply.started":"2021-10-18T13:51:22.259257Z","shell.execute_reply":"2021-10-18T13:51:22.548785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h2 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Loss Function</h2>","metadata":{}},{"cell_type":"code","source":"def criterion(outputs, targets):\n    return torch.sqrt(nn.MSELoss()(outputs.view(-1), targets.view(-1)))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:22.551185Z","iopub.execute_input":"2021-10-18T13:51:22.551462Z","iopub.status.idle":"2021-10-18T13:51:22.555772Z","shell.execute_reply.started":"2021-10-18T13:51:22.551426Z","shell.execute_reply":"2021-10-18T13:51:22.555033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h2 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Training Function</h2>","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n    scaler = amp.GradScaler()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, (images, targets) in bar:         \n        images = images.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        \n        batch_size = images.size(0)\n        \n        with amp.autocast(enabled=True):\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n            loss = loss / CONFIG['n_accumulate']\n            \n        scaler.scale(loss).backward()\n    \n        if (step + 1) % CONFIG['n_accumulate'] == 0:\n            scaler.step(optimizer)\n            scaler.update()\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            if scheduler is not None:\n                scheduler.step()\n                \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        \n        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n                        LR=optimizer.param_groups[0]['lr'])\n    gc.collect()\n    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:22.557145Z","iopub.execute_input":"2021-10-18T13:51:22.557638Z","iopub.status.idle":"2021-10-18T13:51:22.568689Z","shell.execute_reply.started":"2021-10-18T13:51:22.557589Z","shell.execute_reply":"2021-10-18T13:51:22.567795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h2 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Validation Function</h2>","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef valid_one_epoch(model, dataloader, device, epoch):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    TARGETS = []\n    PREDS = []\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, (images, targets) in bar:        \n        images = images.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        \n        batch_size = images.size(0)\n        \n        outputs = model(images)\n        loss = criterion(outputs, targets)\n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        \n        PREDS.append(outputs.view(-1).cpu().detach().numpy())\n        TARGETS.append(targets.view(-1).cpu().detach().numpy())\n        \n        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n                        LR=optimizer.param_groups[0]['lr'])   \n    \n    TARGETS = np.concatenate(TARGETS)\n    PREDS = np.concatenate(PREDS)\n    val_rmse = mean_squared_error(TARGETS, PREDS, squared=False)\n    gc.collect()\n    \n    return epoch_loss, val_rmse","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:22.570033Z","iopub.execute_input":"2021-10-18T13:51:22.570309Z","iopub.status.idle":"2021-10-18T13:51:22.581804Z","shell.execute_reply.started":"2021-10-18T13:51:22.570273Z","shell.execute_reply":"2021-10-18T13:51:22.58095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h2 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Run Training</h2>","metadata":{}},{"cell_type":"code","source":"def run_training(model, optimizer, scheduler, device, num_epochs):\n    # To automatically log gradients\n    wandb.watch(model, log_freq=100)\n    \n    if torch.cuda.is_available():\n        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n    \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_rmse = np.inf\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs + 1): \n        gc.collect()\n        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n                                           dataloader=train_loader, \n                                           device=CONFIG['device'], epoch=epoch)\n        \n        val_epoch_loss, val_epoch_rmse = valid_one_epoch(model, valid_loader, \n                                                         device=CONFIG['device'], \n                                                         epoch=epoch)\n    \n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(val_epoch_loss)\n        history['Valid RMSE'].append(val_epoch_rmse)\n        \n        # Log the metrics\n        wandb.log({\"Train Loss\": train_epoch_loss})\n        wandb.log({\"Valid Loss\": val_epoch_loss})\n        wandb.log({\"Valid RMSE\": val_epoch_rmse})\n        \n        print(f'Valid RMSE: {val_epoch_rmse}')\n        \n        # deep copy the model\n        if val_epoch_rmse <= best_epoch_rmse:\n            print(f\"{c_}Validation Loss Improved ({best_epoch_rmse} ---> {val_epoch_rmse})\")\n            best_epoch_rmse = val_epoch_rmse\n            run.summary[\"Best RMSE\"] = best_epoch_rmse\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = \"RMSE{:.4f}_epoch{:.0f}.bin\".format(best_epoch_rmse, epoch)\n            torch.save(model.state_dict(), PATH)\n            # Save a model file from the current directory\n            wandb.save(PATH)\n            print(f\"Model Saved{sr_}\")\n            \n        print()\n    \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best RMSE: {:.4f}\".format(best_epoch_rmse))\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:22.583222Z","iopub.execute_input":"2021-10-18T13:51:22.583505Z","iopub.status.idle":"2021-10-18T13:51:22.597033Z","shell.execute_reply.started":"2021-10-18T13:51:22.583469Z","shell.execute_reply":"2021-10-18T13:51:22.596253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_loaders(fold):\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    \n    train_dataset = PawpularityDataset(TRAIN_DIR, df_train, transforms=data_transforms['train'])\n    valid_dataset = PawpularityDataset(TRAIN_DIR, df_valid, transforms=data_transforms['valid'])\n\n    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n                              num_workers=4, shuffle=True, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n                              num_workers=4, shuffle=False, pin_memory=True)\n    \n    return train_loader, valid_loader","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:22.598496Z","iopub.execute_input":"2021-10-18T13:51:22.598952Z","iopub.status.idle":"2021-10-18T13:51:22.60839Z","shell.execute_reply.started":"2021-10-18T13:51:22.598911Z","shell.execute_reply":"2021-10-18T13:51:22.607633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fetch_scheduler(optimizer):\n    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n                                                   eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n                                                             eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == None:\n        return None\n        \n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:22.609724Z","iopub.execute_input":"2021-10-18T13:51:22.610019Z","iopub.status.idle":"2021-10-18T13:51:22.620021Z","shell.execute_reply.started":"2021-10-18T13:51:22.609983Z","shell.execute_reply":"2021-10-18T13:51:22.619246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Create Dataloaders</span>","metadata":{}},{"cell_type":"code","source":"train_loader, valid_loader = prepare_loaders(fold=0)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:22.621085Z","iopub.execute_input":"2021-10-18T13:51:22.621337Z","iopub.status.idle":"2021-10-18T13:51:22.643969Z","shell.execute_reply.started":"2021-10-18T13:51:22.621302Z","shell.execute_reply":"2021-10-18T13:51:22.643313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Define Optimizer and Scheduler</span>","metadata":{}},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\nscheduler = fetch_scheduler(optimizer)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:22.645041Z","iopub.execute_input":"2021-10-18T13:51:22.645445Z","iopub.status.idle":"2021-10-18T13:51:22.662007Z","shell.execute_reply.started":"2021-10-18T13:51:22.64541Z","shell.execute_reply":"2021-10-18T13:51:22.661125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run = wandb.init(project='Pawpularity', \n                 config=CONFIG,\n                 job_type='Train',\n                 anonymous='must')","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:22.663404Z","iopub.execute_input":"2021-10-18T13:51:22.663849Z","iopub.status.idle":"2021-10-18T13:51:29.379417Z","shell.execute_reply.started":"2021-10-18T13:51:22.663814Z","shell.execute_reply":"2021-10-18T13:51:29.378563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Start Training</span>","metadata":{}},{"cell_type":"code","source":"model, history = run_training(model, optimizer, scheduler,\n                              device=CONFIG['device'],\n                              num_epochs=CONFIG['epochs'])","metadata":{"execution":{"iopub.status.busy":"2021-10-18T13:51:29.383585Z","iopub.execute_input":"2021-10-18T13:51:29.385809Z","iopub.status.idle":"2021-10-18T14:45:12.677322Z","shell.execute_reply.started":"2021-10-18T13:51:29.385766Z","shell.execute_reply":"2021-10-18T14:45:12.676588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run.finish()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-18T14:45:12.678625Z","iopub.execute_input":"2021-10-18T14:45:12.678911Z","iopub.status.idle":"2021-10-18T14:45:17.815453Z","shell.execute_reply.started":"2021-10-18T14:45:12.678875Z","shell.execute_reply":"2021-10-18T14:45:17.814736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Notice that after the 1st epoch the model doesn't learn much. Any suggestions to improve training are welcome</span>","metadata":{}},{"cell_type":"markdown","source":"# <h2 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Visualizations</h2>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\"><a href=\"https://wandb.ai/dchanda/Pawpularity/runs/39ro4emr\">View the Complete Dashboard Here ⮕</a></span>","metadata":{}},{"cell_type":"code","source":"# Code taken from https://www.kaggle.com/ayuraj/interactive-eda-using-w-b-tables\n\n# This is just to display the W&B run page in this interactive session.\nfrom IPython import display\n\n# we create an IFrame and set the width and height\niF = display.IFrame(run.url, width=1000, height=720)\niF","metadata":{"execution":{"iopub.status.busy":"2021-10-18T14:45:17.816915Z","iopub.execute_input":"2021-10-18T14:45:17.81718Z","iopub.status.idle":"2021-10-18T14:45:17.826494Z","shell.execute_reply.started":"2021-10-18T14:45:17.817145Z","shell.execute_reply":"2021-10-18T14:45:17.825754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![Upvote!](https://img.shields.io/badge/Upvote-If%20you%20like%20my%20work-07b3c8?style=for-the-badge&logo=kaggle)","metadata":{}}]}